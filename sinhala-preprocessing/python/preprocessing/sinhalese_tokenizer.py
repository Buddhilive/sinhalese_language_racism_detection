import re

import emoji

from preprocessing.sinhalese_characters import get_simplified_character


def replace_url(text: str) -> str:
    """
    replace URL of a text
    :param text: text to replace urls
    :return: url removed text
    """
    return re.sub(r'(http://www\.|https://www\.|http://|https://)[a-z0-9]+([\-.]{1}[a-z0-9A-Z/]+)*', '', text)


def remove_retweet_state(text: str) -> str:
    """
    remove retweet states in the beginning such as "RT @sam92ky: "
    :param text: text
    :return: text removed retweets state
    """
    return re.sub(r'^RT @\w*: ', '', text)


def replace_mention(text: str) -> str:
    return re.sub(r'@\w*', 'PERSON', text)


def split_tokens(text: str) -> list:
    """
    tokenize text
    :param text: text
    :return: token list
    """
    # text characters to split is from: https://github.com/madurangasiriwardena/corpus.sinhala.tools
    return [token for token in
            re.split(r'[., ¬∏‚Äö\"/|‚Äî¬¶‚Äù‚Äò\'‚Äú‚Äô¬¥!@#$%^&*+\-¬£?Àú()\[\]{\}:;‚Äì√ä¬†‚ÄÉÔøΩÔÄ†ÔÅ≥ÔÅ¨ÔÜê‚Ä™‚Ä¨‚Äè0123456789]', text) if
            token != ""]


def set_spaces_among_emojis(text: str) -> str:
    """
    make spaces among emojis to tokenize them
    :param text: text to be modified
    :return: modified text
    """
    modified_text = ""
    for c in text:
        modified_text += c
        if c in emoji.UNICODE_EMOJI:
            modified_text += " "

    return modified_text


def simplify_sinhalese_text(text: str) -> str:
    """
    simplify
    :param text:
    :return:
    """
    modified_text = ""
    for c in text:
        modified_text += get_simplified_character(c)
    return modified_text


def stem_word(word: str) -> str:
    """
    Stemming words
    :param word: word
    :return: stemmed word
    """
    if len(word) < 4:
        return word

    # remove '‡∂ß'
    if word[-1] == '‡∂ß':
        return word[:-1]

    # remove '‡∂Ø'
    if word[-1] == '‡∂Ø':
        return word[:-1]

    # remove '‡∂ß‡∂≠‡∑ä'
    if word[-3:] == '‡∂ß‡∂≠‡∑ä':
        return word[:-3]

    # remove '‡∂ö‡∑ä'
    if word[-2:] == '‡∂ö‡∑ä':
        return word[:-2]

    # remove '‡∂ú‡∑ô' (instead of ‡∂ú‡∑ö because this step comes after simplifying text)
    if word[-2:] == '‡∂ú‡∑ô':
        return word[:-2]

    # else
    return word


def tokenize(text: str) -> list:
    return [stem_word(token) for token in split_tokens(set_spaces_among_emojis(replace_url(replace_mention(
        simplify_sinhalese_text(remove_retweet_state(text).lower())))))]


# txt = "RT @sam92ky: ‡∂ö‡∑í‡∂∫‡∑Ä‡∂±‡∑ä‡∂±..‡∂ª‡∂ß‡∑ö Renuka ‡∂≠‡∑è‡∂≠‡∑ä‡∂≠‡∂ß‡∂≠‡∑ä ‡∂Ø‡∑î‡∂¥‡∑ä‡∂¥‡∂≠‡∑è‡∂ß @indika27 @P0dda ‡∂∏‡∑í‡∂±‡∑í‡∑É‡∑ä‡∑É‡∑î ‡∂ö‡∑î‡∂´‡∑î ‡∂Ø‡∑è‡∂±‡∑ä‡∂±‡∑ö ‡∂∏‡∑ñ‡∑Ñ‡∑ñ‡∂Ø‡∂ß ‡∂±‡∑ô.,.... ‡∂í‡∂ö‡∂∫‡∑í " \
#       "‡∂∏‡∑ô https://t.co/xDrwvDa3yr ‡∂î‡∂ö‡∑ä‡∂ö‡∑ú‡∂∏ https://t.co/xDrwvDa3yr case. Sighhhhhhhh  üò¢ " \
#       "‡∑Ñ‡∑É‡∑ä‡∂∂‡∂±‡∑ä‡∂©‡∑ä‡∂ú‡∑ö ‡∂Ø‡∑Ä‡∑É‡∂ö‡∑ä ‡∂ã‡∂±‡∂≠‡∑ä {‡∂ë‡∂ö‡∂∫‡∑í}***-+‡∂±‡∑ú‡∑Ä‡∑î‡∂±‡∂≠‡∑ä [‡∂ë‡∂ö‡∂∫‡∑í ‡∂Ö‡∂¥‡∑í‡∂ß] ‡∑É‡∑ù‡∂±‡∑ä‡∂ú‡∑ä üòÇüòÇüòÇüå∫ ‡∂¥‡∑î‡∂ö‡∂Ø ‡∂∫‡∑è‡∂Ω‡∑î‡∑Ä‡∑ö.. üòú #RT #Help"
# print(tokenize(txt))
